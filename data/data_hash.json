[
  {
    "Name":"Craigslist",
    "Team":"",
    "Wisdom":"",
    "Notes":"2.5+ B archived postings. MongoDB has 3 shards across 3 node replicasets. 6TB of data. Search has 300+M daily queries.",
    "PM":"",
    "OS":"",
    "DevOps":"Perl",
    "Infrastructure":"Self-hosted, Blades and multi-U multi-disk RAID boxes. Mostly local storage. All open source tools.",
    "Storage":"XFS",
    "CDN":"",
    "Servers":"Apache, mod_perl, HAProxy (between DB clients and servers)",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"Memcached (primary for rendered pages, serliazed objects)",
    "BETechnology":"perl+epoll",
    "BEFrameworks":"Perl",
    "BECaching":"Redis (remote replication, 80% in sorted sets, shared multi-node cluster)",
    "DB":"MySQL (live postings), MongoDB (archived postings, built in sharding support and good replica sets, also has good Perl support)",
    "DBNotes":"InnoDB compression used almost everywhere",
    "Queues":"Redis",
    "Search":"Sphinx",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://www.slideshare.net/jzawodn/living-with-sql-and-nosql-at-craigslist-a-pragmatic-approach http://blog.zawodny.com/2011/02/26/redis-sharding-at-craigslist/ http://www.mongodb.com/presentations/lessons-learned-migrating-2-billion-documents-craigslist"
  },
  {
    "Name":"Instagram",
    "Team":"5",
    "Wisdom":"Simplicity. Do'nt re-invent. SSL only at LB",
    "Notes":"100+ EC2 servers. 25+ Django servers. 12+12 DB servers.6 memcached servers. 200 python queue workers.",
    "PM":"",
    "OS":"Ubuntu",
    "DevOps":"Fabric, Vmtouch, Munin, StatsD,Pingdom, PagerDuty, Sentry, pgfouine, DogSlow",
    "Infrastructure":"AWS, ELB, Route53",
    "Storage":"XFS, S3,EBS",
    "CDN":"CloudFront",
    "Servers":"Gunicorn, NGinx, HAProxy",
    "FETechnology":"Python",
    "FEFrameworks":"Django",
    "FECaching":"Memcached",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"Redis",
    "DB":"PostgreSQL",
    "DBNotes":"Sharing by User ID, Pgbouncer",
    "Queues":"",
    "Search":"Solr",
    "Graph":"Redis",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2012/4/9/the-instagram-architecture-facebook-bought-for-a-cool-billio.html"
  },
  {
    "Name":"Twitter",
    "Team":"Platform team - 5-7, sit together, dedicated, can publically accept trust, autonomous. Failure is an option.",
    "Wisdom":"Test before you start, Tests will save your life. Denormalize a lot. Use messages to invalidate Cache. Cache everything. Build in limits. Partition day 1. Avoid complex joins and scans. SOA = seperate concerns but will introduce cross dependencies.",
    "Notes":"300 tweets/s . 3 queues to LB requests. 600 req/s, 200300 connections per second, MySQL handles 2400 requests/s, 180 rails instances, 1 big MySQL server, 30+ jobs processes, Rails SLA 200 ms, Avg DB time 50-100ms, 16gb of memcached. 90% requests are API.",
    "PM":"",
    "OS":"",
    "DevOps":"VIZ, Zipkin, Yourkit, JConsole, track realtime statistics, AWStats, Google Analytics",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Ruby (api, web, monorail - was single stack - bad i/o, too many dev, brittle)",
    "FEFrameworks":"Rails",
    "FECaching":"Memcached, Varnish",
    "BETechnology":"Scala (Tweet, User, Timeline, Graph, DMS services)",
    "BEFrameworks":"Finagle (author), Zookeeper, Thrift (author)",
    "BECaching":"Redis, T-Bird, Flock",
    "DB":"MySQL",
    "DBNotes":"",
    "Queues":"Kestrel, drb/Jabber, Rinda",
    "Search":"",
    "Graph":"Flock, Redis",
    "Analytics":"Storm (Author)",
    "Reference":"http://www.artima.com/scalazine/articles/twitter_on_scala.html http://gojko.net/2009/03/16/qcon-london-2009-upgrading-twitter-without-service-disruptions/ http://www.slideshare.net/Blaine/scaling-twitter http://www.infoq.com/presentations/twitter-scalability-culture"
  },
  {
    "Name":"NY Times",
    "Team":"",
    "Wisdom":"",
    "Notes":"200ms request SLA. Ea python websocket gateway supports 100k clients. 12 nodes Cassandra cluster across 2 regions. Cassandra for persistence and cache",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"AWS (Oregon, Dublin) Amazon Linux AMI. c1-m for retail,  MQ on c1-xl",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Python, Php",
    "FEFrameworks":"sockjs",
    "FECaching":"Cassandra",
    "BETechnology":"Python, Java",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"Cassandra",
    "DBNotes":"",
    "Queues":"RabbitMQ, Fabrik",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2014/1/13/nytimes-architecture-no-head-no-master-no-single-point-of-fa.html"
  },
  {
    "Name":"Hip Chat",
    "Team":"18",
    "Wisdom":"EBS 1TB data max. Couch uses 2x disk space during compaction. Riak search not baked, prefer ElasticSearch.",
    "Notes":"60 msg/s, 1.2B documents, 4TB EBS Raid, 26 frontend proxies, 52 backend app servers. 0.5TB search data. 75 AWS EC2 instances. 6 XMPP servers. Redis clustering pain.1B messages, 200gb RAM. AWS on 4 zones. 22gb of heap on 8 boxes for Java.",
    "PM":"",
    "OS":"Ubuntu",
    "DevOps":"Chef, Fabric, Capistrano, Bamboo, Sensu, Monit, PergerDuty, statsD, Graphite graphing.",
    "Infrastructure":"AWS",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Php",
    "FEFrameworks":"Twisted Python XMPP",
    "FECaching":"Redis",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"CouchDB (Chat history, moving to ElasticSearch)",
    "DB":"MySQL (MariaDB for on premise)",
    "DBNotes":"",
    "Queues":"German (queue), Curler (worker), Evaluating RabbitMQ",
    "Search":"Lucene (was), ElasticSearch",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2014/1/6/how-hipchat-stores-and-indexes-billions-of-messages-using-el.html"
  },
  {
    "Name":"ESPN",
    "Team":"24",
    "Wisdom":"Cache at page and fragment level. Multi-cache system. avoid TTL expiration.",
    "Notes":"#10 of all sites.100k req/s. Sports data XGb. 100s of logical DBs,150 apps on 100 servers. 100s of JVM per server.",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"F5 LB, Disney datacenter",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Java",
    "FEFrameworks":"",
    "FECaching":"Ehcache (replicated per app server, DB trigger, changes pushed), Oracle eXtreme Scale",
    "BETechnology":"Java",
    "BEFrameworks":"Hibernate, EJB",
    "BECaching":"Hibernate caching, JPA Query replicator.",
    "DB":"Oracle, MS SQL",
    "DBNotes":"",
    "Queues":"Oracle AQ, WebphereMQ, JMS",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2013/11/4/espns-architecture-at-scale-operating-at-100000-duh-nuh-nuhs.html"
  },
  {
    "Name":"SalesForce",
    "Team":"",
    "Wisdom":"Multi-tenancy, Stateless, DB is System of Record, No DDL",
    "Notes":"1.3B daily transactions, 15k hw systems, 14GB heap per JVM. 8 node DB cluster. CUstomer sandbox have 4 node cluster. ACS curcor cache on dedicated 2 servers.",
    "PM":"",
    "OS":"Linux",
    "DevOps":"Puppet, Razor, Nagios, Perforce, Git, svn",
    "Infrastructure":"",
    "Storage":"22PB faw SAN storage, 5KSAN ports. QFS",
    "CDN":"",
    "Servers":"Jetty",
    "FETechnology":"Python",
    "FEFrameworks":"",
    "FECaching":"Memcached",
    "BETechnology":"Python, Perl",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"Oracle RAC",
    "DBNotes":"OrgID partition, Creative Denormaization.",
    "Queues":"Qpid",
    "Search":"Solr with 640GB Flash mem",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2013/9/23/salesforce-architecture-how-they-handle-13-billion-transacti.html http://www.infoq.com/presentations/SalesForce-Multi-Tenant-Architecture-Craig-Weissman"
  },
  {
    "Name":"Yelp",
    "Team":"",
    "Wisdom":"if doing something clever, its wrong.",
    "Notes":"102m monthly uniq visitors.",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"AWS",
    "Storage":"S3",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"Shard based on account ID",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"AWS Elastic MapReduce, Hadoop",
    "Reference":"http://highscalability.com/blog/2012/1/9/the-etsy-saga-from-silos-to-happy-to-billions-of-pageviews-a.html"
  },
  {
    "Name":"Etsy",
    "Team":"From Flickr",
    "Wisdom":"QA is done by developers. Ea. Dev on support call 1wk/yr. Always 1Ops/1Dev on call. 1d/wk for schema change. Let Dev code SQL avoid DBA dependency.",
    "Notes":"2B page views/mo",
    "PM":"",
    "OS":"CentOS",
    "DevOps":"Chef, statsD (authored)",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Php (was Python)",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"Php (was Python)",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"MySQL (was PostgreSQL)",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2012/1/9/the-etsy-saga-from-silos-to-happy-to-billions-of-pageviews-a.html"
  },
  {
    "Name":"Facebook",
    "Team":"",
    "Wisdom":"PODs of DB, Webapps",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Php",
    "FEFrameworks":"Hiphop VM",
    "FECaching":"",
    "BETechnology":"Java",
    "BEFrameworks":"Thrift",
    "BECaching":"",
    "DB":"MySQL",
    "DBNotes":"Zookeeper",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"Hadoop, HBase (Rejected Cassandra), Scribe for logs, Ptail reads data in.",
    "Reference":"http://highscalability.com/blog/2011/5/17/facebook-an-example-canonical-architecture-for-scaling-billi.html"
  },
  {
    "Name":"SoundCloud",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":""
  },
  {
    "Name":"Google",
    "Team":"",
    "Wisdom":"",
    "Notes":"TBs of data on 1000 machines",
    "PM":"",
    "OS":"Linux",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"GFS",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Python",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"Java, C++",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"MapReduce, BigTable",
    "Reference":""
  },
  {
    "Name":"NetFlix",
    "Team":"",
    "Wisdom":"Unit Test everything",
    "Notes":"33% of al US internet traffic, 10s of 1000s of instances",
    "PM":"",
    "OS":"",
    "DevOps":"vmstat, dstat, mpstat, top, atop, htop, nmon, iostat, sar, uptime, free, pidstat, ps, pstree, netstat, iptraf, ping, nicstat, ifconfig, pmap, pstack, jstack, iotop, tcpdump, wireshark, strace. Test Branch ()dev features, Release Branch (weekly release), Prod Branch (merge from Release, for daily patches), gcviz (author), Jenkins, Maven",
    "Infrastructure":"AWS",
    "Storage":"S3",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Java",
    "FEFrameworks":"Bootstrap, JQueryUI, D3, DataTables, FreeMarker, Pytheas (author), Guice, Jersey",
    "FECaching":"Memcached, EVCache (author)",
    "BETechnology":"Clojure, Java, Python",
    "BEFrameworks":"Thrift, Zuul",
    "BECaching":"Cassandra (was simpleDB) for User Video Queue",
    "DB":"MySQL",
    "DBNotes":"",
    "Queues":"Kafka, Suro",
    "Search":"ElasticSearch",
    "Graph":"",
    "Analytics":"Pig, Hive, Hadoop, Storm",
    "Reference":"http://techblog.netflix.com/ http://www.slideshare.net/RuslanMeshenberg/svc-202netflixopensource http://www.slideshare.net/RuslanMeshenberg/arc305-how-netflix-leverages-multiple-regions-to-increase-availability-an-isthmus-and-activeactive-case-study http://techblog.netflix.com/2013/12/announcing-suro-backbone-of-netflixs.html http://techblog.netflix.com/2013/08/deploying-netflix-api.html http://techblog.netflix.com/2013/05/garbage-collection-visualization.html"
  },
  {
    "Name":"StackExchange/Overflow",
    "Team":"45",
    "Wisdom":"Run in RAM.",
    "Notes":"10 servers in NY, 9 production servers.Overflow has more SSD and RAM for Lucene. Failover is read only. 60% peak for webservers not acceptable. SQL server - 13TB Ram, 20gb a day goes into SQL server. Create 1 table a day for stats.",
    "PM":"",
    "OS":"Linux",
    "DevOps":"Dashboard - 3 graphs: CPI, memory, network. Orion monitor. Google Anaytics. Nagios. Splunk for logs. Bind for DNS, Pingdom.",
    "Infrastructure":"Peer1. Don't trust AWS. 3x more expensive. Expect 5 yrs from each computer. AWS has random network latency issues.",
    "Storage":"",
    "CDN":"CDN helps 80% of the way with international customers.",
    "Servers":"HAProxy, Bacula",
    "FETechnology":"C#",
    "FEFrameworks":"Razor, jQuery",
    "FECaching":"Redis",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"Redis as shared state cache between 10 servers.",
    "DB":"MS SQL Server. 40% read, 60% write.",
    "DBNotes":"",
    "Queues":"",
    "Search":"Lucene",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://blog.serverfault.com/ http://highscalability.com/blog/2011/10/24/stackexchange-architecture-updates-running-smoothly-amazon-4.html http://highscalability.com/blog/2011/3/3/stack-overflow-architecture-update-now-at-95-million-page-vi.html"
  },
  {
    "Name":"AirBnB",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":""
  },
  {
    "Name":"Tumblr",
    "Team":"20",
    "Wisdom":"Light Scrum, Automate everything. MySQL/Sharding scales - apps dont, Select a stack that will help you hire the people you need. Read.",
    "Notes":"40k req/s, 1TB into Hadoop, 500m page views. 500 web servers with Apache and Php, 200 DB servers, 47 pools, 30 shards, 30 memcached servers, 22 redis servers w/8-32 instances each, 15 varnish servers, 25 HAProxy nodes, 8 NGinx, 14 queue servers",
    "PM":"",
    "OS":"Linux",
    "DevOps":"Git, Capistrano, Puppet, jenkins, preconfigued Dev machines updated via puppet. Vim and Textmate, Code Reviews",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"HAProxy (front end), NGinx",
    "FETechnology":"Php, Ruby",
    "FEFrameworks":"Moved from Handlebars and Prototype to Jquery and underscore",
    "FECaching":"Varnish (blogs), Memcached (moving to redis)",
    "BETechnology":"Scala (was Php), some Clojure",
    "BEFrameworks":"Finagle, Thrift, Func (author), Zookeeper",
    "BECaching":"Redis (also for queues)",
    "DB":"MySQL (NOT replacing with HBase, Feel it can scale just as well as MongoDB)",
    "DBNotes":"",
    "Queues":"Kafka, Gearman, Kestrel",
    "Search":"",
    "Graph":"",
    "Analytics":"HBase",
    "Reference":"http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html http://engineering.tumblr.com/"
  },
  {
    "Name":"Pinterest",
    "Team":"40",
    "Wisdom":"Shard if project will have few TB",
    "Notes":"180 web engines, 240 API engines, 88 MySQL DB(cc2.8xlarge) +1 slave, 110 Redis, 200 memcached instances, 4 Redis Task Managers, 80 Task processors, Shareded Solr",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"AWS, Akamai, Level3",
    "Storage":"",
    "CDN":"CloudFront",
    "Servers":"NGinx",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"Memcached (mature, simple, nver crashes)",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"Redis (not mature, but goodm variety of data structures, persistence and replication) ",
    "DB":"MySQL (very mature, never crashed for them)",
    "DBNotes":"XtraBackup, Innotop, Maatkit, Percona supported   CLUSTERING - Membase and Cassandra (clustering, automatic, no single point of failure, load balancing but not matrure, hard to find engineers, scary upgrades, complex) SHARDING - manual distribution, can split DB for capacity, high availability, load balancing, simpler. ",
    "Queues":"Redis",
    "Search":"Solr (Doesnt scale past one box, easy to setup, now using http://websolr.com ) ElasticSearch gave trouble with small documents and lots of queries",
    "Graph":"",
    "Analytics":"HBase",
    "Reference":"http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html  http://highscalability.com/blog/2012/5/21/pinterest-architecture-update-18-million-visitors-10x-growth.html"
  },
  {
    "Name":"Yahoo",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":""
  },
  {
    "Name":"Khan Academy",
    "Team":"5",
    "Wisdom":"",
    "Notes":"6mil users a month",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"Google Apps (more automatic scalaingvs AWS, nneds manual effort)",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Php",
    "FEFrameworks":"Processing.js",
    "FECaching":"",
    "BETechnology":"Python",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2013/4/1/khan-academy-checkbook-scaling-to-6-million-users-a-month-on.html"
  },
  {
    "Name":"DuckDuckGo",
    "Team":"Asana (pm), Hipchat, Yammer10-15 FT, 20-25 contrib, 50% FT remote",
    "Wisdom":"",
    "Notes":"30m searches in 2/12. 12m API requests a day., 1m searches a day. Each dev gets medium instance. Use m2.xlarge for caching, 100gb shared across multiple instances. No master cache, relicated on all.",
    "PM":"",
    "OS":"Ubuntu",
    "DevOps":"Perl, ServerDensity (monitoring), daemontools, git",
    "Infrastructure":"AWS, Global Traffic Director for LB. Dont trust EBS",
    "Storage":"S3, Berkley DB",
    "CDN":"",
    "Servers":"NGinx, FastCGI",
    "FETechnology":"Perl, Javascript, Node.js",
    "FEFrameworks":"YUI (moving to jQuery)",
    "FECaching":"Memcached. Cache rate is 50%",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"Bucardo (pgSQL replication)",
    "DB":"PostgreSQL",
    "DBNotes":"",
    "Queues":"",
    "Search":"Solr, Perl",
    "Graph":"",
    "Analytics":"",
    "Reference":"https://duck.co/help/company/architecture http://highscalability.com/blog/2013/1/28/duckduckgo-architecture-1-million-deep-searches-a-day-and-gr.html"
  },
  {
    "Name":"TripAdvisor",
    "Team":"Dev works across entire stack. simple and deploy often. Release process is shared + rotated among various senior Eng and EM.\ntesting -Unit, Functional, Load, Smoke, Selenium, Load, and a test lab. reviews: Design Review, Code Review, Deployment Review, Operational Review",
    "Wisdom":"",
    "Notes":"80 front ends, 52 back ends - each with 24 cores. 12 moderate servers for memcached",
    "PM":"",
    "OS":"",
    "DevOps":"cacti, nagios, custom, php, ruby, python, perl, svn",
    "Infrastructure":"AWS, ELB (See cost analysis in link)",
    "Storage":"",
    "CDN":"",
    "Servers":"NGinx, Tomcat",
    "FETechnology":"Java",
    "FEFrameworks":"Velocity",
    "FECaching":"Memcached",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"Lucene",
    "Graph":"",
    "Analytics":"Hadoop",
    "Reference":"http://highscalability.com/blog/2012/10/2/an-epic-tripadvisor-update-why-not-run-on-the-cloud-the-gran.html"
  },
  {
    "Name":"YouPorn",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"Syslogn",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"NGinx (web server), HAProxy for LB, Varnish (rev Proxy)",
    "FETechnology":"Php (was Perl)",
    "FEFrameworks":"Symfony2, http://www.doctrine-project.org/ for CMS",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"Redis",
    "DB":"MySQL (feeds Redis)",
    "DBNotes":"",
    "Queues":"ActiveMQ",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":""
  },
  {
    "Name":"YouTube",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":""
  },
  {
    "Name":"LinkedIn",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"svn, Hudson, ship code twice a week, ones every 2 wks for major features.",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Ruby, Node.JS",
    "FEFrameworks":"Backbone.js, Dust.js (was YUI), Sass, PhantomJS",
    "FECaching":"",
    "BETechnology":"Java, Scala",
    "BEFrameworks":"Spring",
    "BECaching":"",
    "DB":"MySQL, Voldemort (Like DynamoDB), Expresso",
    "DBNotes":"",
    "Queues":"Kafka (author)",
    "Search":"",
    "Graph":"",
    "Analytics":"hadoop",
    "Reference":"http://engineering.linkedin.com/technology"
  },
  {
    "Name":"New Relic",
    "Team":"30 for 10k customers.",
    "Wisdom":"Trendy != Reliable.",
    "Notes":"",
    "PM":"",
    "OS":"Linux",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"NGinx, Jetty",
    "FETechnology":"Ruby",
    "FEFrameworks":"Rails",
    "FECaching":"",
    "BETechnology":"Java (was Ruby, not performant)",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"MySQL (Percona build)",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2011/7/18/new-relic-architecture-collecting-20-billion-metrics-a-day.html"
  },
  {
    "Name":"EverNote",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"Debian",
    "DevOps":"Zabbix, Opsview, AlertSite, Puppet, http://graphite.wikidot.com/, collectD",
    "Infrastructure":"BGP for DNS, Vyatta LB thru Level3",
    "Storage":"",
    "CDN":"",
    "Servers":"Tomcat",
    "FETechnology":"",
    "FEFrameworks":"GWT, prototype, JQuery",
    "FECaching":"EHCache",
    "BETechnology":"Java",
    "BEFrameworks":"Hibernate, EJB3, Thrift",
    "BECaching":"",
    "DB":"MySQL",
    "DBNotes":"",
    "Queues":"",
    "Search":"Lucene",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://blog.evernote.com/tech/2011/05/17/architectural-digest/ http://blog.evernote.com/tech/page/2/"
  },
  {
    "Name":"Disqus",
    "Team":"",
    "Wisdom":"",
    "Notes":"17,000 req/s, 100 servers, 30% web. 10% DB, 25% cache, 20% LB, 15% utility",
    "PM":"",
    "OS":"",
    "DevOps":"Python, Hudson",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"Apache + mod_wsgi, HAProxy",
    "FETechnology":"Python",
    "FEFrameworks":"Django",
    "FECaching":"memcached",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"PostgreSQL",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2010/10/26/scaling-disqus-to-75-million-comments-and-17000-rps.html  http://www.slideshare.net/zeeg/djangocon-2010-scaling-disqus"
  },
  {
    "Name":"Reddit",
    "Team":"",
    "Wisdom":"Seperation of services, open schema, STATELESS, Memcache everything (store more data now in Memcachedb than Postgres)",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"AWS",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"memcached",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"Cassandra (votes)",
    "DB":"PostgreSQL (most data)",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2010/5/17/7-lessons-learned-while-building-reddit-to-270-million-page.html  http://www.reddit.com/#Whattechnologydoesreddituse"
  },
  {
    "Name":"eBay",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"Node.js",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"MongoDB",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://www.technology-ebay.de/the-teams/mobile-de/blog/mapping-bigdecimals-with-morphia-for-mongodb.html http://www.ebaytechblog.com/2013/05/17/how-we-built-ebays-first-node-js-application/ http://www.mongodb.com/presentations/storing-ebays-media-metadata-mongodb-0 http://www.mongodb.com/presentations/mongodb-ebay"
  },
  {
    "Name":"MetLife",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"MongoDB",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://www.mongodb.org/about/production-deployments/"
  },
  {
    "Name":"Stripe",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"MongoDB",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://www.mongodb.org/about/production-deployments/"
  },
  {
    "Name":"ServerDensity",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"MongoDB",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://www.mongodb.org/about/production-deployments/"
  },
  {
    "Name":"FourSquare",
    "Team":"",
    "Wisdom":"Cache and LB across a cluster. Design scalable upfront., Release early and often",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"AWS",
    "Storage":"Isilon Cluster",
    "CDN":"",
    "Servers":"Tomcat",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"Java, Scala",
    "BEFrameworks":"Finagle, Zookeeper, Thrift",
    "BECaching":"Oracle MemoryGrid",
    "DB":"MongoDB",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2010/10/15/troubles-with-sharding-what-can-we-learn-from-the-foursquare.html http://nosql.mypopescu.com/post/1265191137/foursquare-mongodb-outage-post-mortem"
  },
  {
    "Name":"Flickr",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/flickr-architecture"
  },
  {
    "Name":"BaseCamp",
    "Team":"",
    "Wisdom":"",
    "Notes":"30 servers, 8CPU ea, = 100 CPU 200gb of Ram",
    "PM":"",
    "OS":"Linux",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"S3",
    "CDN":"",
    "Servers":"HAProxy, Apache, Mongrel",
    "FETechnology":"Ruby",
    "FEFrameworks":"Rails (author)",
    "FECaching":"memcached",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"MySQL",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":""
  },
  {
    "Name":"Digg",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":"http://highscalability.com/blog/2009/4/4/digg-architecture.html"
  },
  {
    "Name":"K12",
    "Team":"",
    "Wisdom":"",
    "Notes":"65,000/req/min - for main server, 3m visits per day, 400000 unique visitors a day",
    "PM":"",
    "OS":"Linux",
    "DevOps":"Jenkins, VMWare",
    "Infrastructure":"",
    "Storage":"NAS",
    "CDN":"",
    "Servers":"Tomcat, Apache",
    "FETechnology":"Java",
    "FEFrameworks":"Struts, Seam, SpringMVC",
    "FECaching":"",
    "BETechnology":"Java",
    "BEFrameworks":"SpringMVC, Hibernate, myBatis",
    "BECaching":"",
    "DB":"Oracle",
    "DBNotes":"",
    "Queues":"JMS",
    "Search":"",
    "Graph":"",
    "Analytics":"Oracle BI",
    "Reference":""
  },
  {
    "Name":"Heroku",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":""
  },
  {
    "Name":"Groupon",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"",
    "Storage":"",
    "CDN":"",
    "Servers":"",
    "FETechnology":"",
    "FEFrameworks":"",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"Storm",
    "Reference":""
  },
  {
    "Name":"Intuit TurboTax",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"AWS",
    "Storage":"",
    "CDN":"CloudFront",
    "Servers":"Apache, Coyote",
    "FETechnology":"JSP",
    "FEFrameworks":"Angular, JSquery, Modernizer, SCSS",
    "FECaching":"",
    "BETechnology":"",
    "BEFrameworks":"",
    "BECaching":"",
    "DB":"",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":""
  },
  {
    "Name":"rocket.im",
    "Team":"",
    "Wisdom":"",
    "Notes":"",
    "PM":"",
    "OS":"",
    "DevOps":"",
    "Infrastructure":"AWS",
    "Storage":"S3",
    "CDN":"",
    "Servers":"NGinx",
    "FETechnology":"Node.js (express, faye, knox, async, underscore, mongoose, redis) did not like socket.io and sockjs",
    "FEFrameworks":"Backbone, requireJS, jQuery",
    "FECaching":"",
    "BETechnology":"App/pubsub/worker/upload worker/mission control",
    "BEFrameworks":"",
    "BECaching":"Redis",
    "DB":"MongoDB",
    "DBNotes":"",
    "Queues":"",
    "Search":"",
    "Graph":"",
    "Analytics":"",
    "Reference":""
  }
]
